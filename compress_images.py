"""
Title: Compress Images
Description: This script compresses images in a specified directory using the Pillow library.
Author: Hsu, Yao-Chih
Version: 1140617
References:
"""

import os
import shutil
import csv
import time
from datetime import datetime
from PIL import Image, ImageFile
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from collections import defaultdict

ImageFile.LOAD_TRUNCATED_IMAGES = True

image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff', '.gif', '.avif', '.heic']

def should_skip(filename):
    name, _ = os.path.splitext(filename)
    return name.endswith('_original') or name.endswith('_skip')

def is_image(file_path):
    try:
        with Image.open(file_path) as img:
            img.verify()
        return True
    except Exception:
        return False

def compress_image(file_path):
    foldername = os.path.dirname(file_path)
    filename = os.path.basename(file_path)
    name, ext = os.path.splitext(filename)
    ext_lower = ext.lower()

    original_dir = os.path.join(foldername, "original image")
    os.makedirs(original_dir, exist_ok=True)
    backup_path = os.path.join(original_dir, f"{name}_original{ext}")

    if os.path.exists(backup_path):
        return (file_path, 0, 0, "å·²å‚™ä»½ï¼Œè·³é", ext_lower, "")

    start_time = time.time()

    try:
        shutil.copy2(file_path, backup_path)
        size_before = os.path.getsize(file_path)

        with Image.open(file_path) as img:
            img.save(file_path, optimize=True, quality=85)

        size_after = os.path.getsize(file_path)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        return (file_path, size_before, size_after, "æˆåŠŸå£“ç¸®", ext_lower, timestamp)

    except Exception as e:
        return (file_path, 0, 0, f"éŒ¯èª¤: {e}", ext_lower, "")

def get_all_images(root_path):
    all_files = []
    for foldername, _, filenames in os.walk(root_path):
        if os.path.basename(foldername).lower() == "original image":
            continue
        for filename in filenames:
            file_path = os.path.join(foldername, filename)
            ext = os.path.splitext(filename)[1].lower()
            if ext in image_extensions and not should_skip(filename) and is_image(file_path):
                all_files.append(file_path)
    return all_files

def process_directory(root_path):
    start_time = datetime.now()


    files = get_all_images(root_path)
    total_before, total_after = 0, 0
    results = []

    print(f"å…±æ‰¾åˆ° {len(files)} å¼µåœ–ç‰‡ï¼Œé–‹å§‹è™•ç†...\n")

    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:
        futures = {executor.submit(compress_image, f): f for f in files}
        for future in tqdm(as_completed(futures), total=len(futures), desc="å£“ç¸®ä¸­"):
            file_path, before, after, status, ext, timestamp = future.result()
            results.append((file_path, before, after, status, ext, timestamp))
            if before and after:
                total_before += before
                total_after += after
            tqdm.write(f"{status} - {file_path}")

        
    end_time = datetime.now()
    elapsed = end_time - start_time


    print("\nğŸ“Š å£“ç¸®çµæœå ±è¡¨ï¼š")
    ext_stats = defaultdict(lambda: {"count": 0, "before": 0, "after": 0})

    for file_path, before, after, status, ext, timestamp in results:
        if before and after:
            savings = before - after
            percent = savings / before * 100
            print(f"{file_path}\n  åŸå§‹å¤§å°: {before/1024:.1f} KB â†’ å£“ç¸®å¾Œ: {after/1024:.1f} KBï¼ˆæ¸›å°‘ {percent:.1f}%ï¼‰")
            ext_stats[ext]["count"] += 1
            ext_stats[ext]["before"] += before
            ext_stats[ext]["after"] += after
        else:
            print(f"{file_path}\n  {status}")

    # åœ–ç‰‡åˆ†é¡çµ±è¨ˆ
    total_files = len(files)
    count_success = sum(1 for r in results if r[3] == "æˆåŠŸå£“ç¸®")
    count_skipped = sum(1 for r in results if "è·³é" in r[3])
    count_error = sum(1 for r in results if r[3].startswith("éŒ¯èª¤"))
    count_unreadable = sum(1 for r in results if r[5] == "") - count_skipped
    count_original_backups = sum(1 for r in results if r[3] == "å·²å‚™ä»½ï¼Œè·³é")

    print(f"\nğŸ“¦ å£“ç¸®ç¸½çµï¼š")
    print(f"â±ï¸ å£“ç¸®é–‹å§‹æ™‚é–“ï¼š{start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"â±ï¸ å£“ç¸®çµæŸæ™‚é–“ï¼š{end_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ•’ ç¸½è€—æ™‚ï¼š{str(elapsed)}")
    print(f"  ç¸½åœ–ç‰‡æ•¸é‡ï¼š{total_files}")
    if count_success > 0:
        avg_time = elapsed.total_seconds() / count_success
        print(f"ğŸ“Š å¹³å‡æ¯å¼µåœ–ç‰‡è™•ç†æ™‚é–“ï¼š{avg_time:.2f} ç§’")
    else:
        print("ğŸ“Š ç„¡æˆåŠŸå£“ç¸®çš„åœ–ç‰‡ï¼Œç„¡æ³•è¨ˆç®—å¹³å‡è™•ç†æ™‚é–“")
    print(f"    âœ” æˆåŠŸå£“ç¸®ï¼š{count_success}")
    print(f"    â­ å·²å‚™ä»½/è·³éï¼š{count_original_backups}")
    print(f"    â¹ _skip å‘½åè·³éï¼š{count_skipped - count_original_backups}")
    print(f"    âŒ åœ–ç‰‡æ‰“é–‹éŒ¯èª¤/éæ”¯æ´ï¼š{count_unreadable}")
    print(f"    âš  å£“ç¸®éŒ¯èª¤ï¼š{count_error}")

    print(f"\n  åŸå§‹ç¸½å¤§å°: {total_before / 1024 / 1024:.2f} MB")
    print(f"  å£“ç¸®å¾Œå¤§å°: {total_after / 1024 / 1024:.2f} MB")
    if total_before:
        print(f"  ç¯€çœç©ºé–“: {(total_before - total_after) / 1024 / 1024:.2f} MBï¼ˆæ¸›å°‘ {((total_before - total_after) / total_before * 100):.1f}%ï¼‰")

    # å‰¯æª”åé¡å‹çµ±è¨ˆ
    print(f"\nğŸ“ å„å‰¯æª”åé¡å‹çµ±è¨ˆï¼š")
    for ext, stats in ext_stats.items():
        before_mb = stats["before"] / 1024 / 1024
        after_mb = stats["after"] / 1024 / 1024
        savings = before_mb - after_mb
        percent = (savings / before_mb * 100) if before_mb > 0 else 0
        print(f"  {ext.upper():<6}ï¼š{stats['count']} å¼µ  ç¯€çœ {savings:.2f} MBï¼ˆ{percent:.1f}%ï¼‰")


    # â• è¼¸å‡º CSV å ±è¡¨
    csv_path = os.path.join(root_path, "å£“ç¸®å ±è¡¨.csv")
    with open(csv_path, mode='w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)

        # ç¬¬ä¸€æ®µï¼šç¸½çµçµ±è¨ˆ
        writer.writerow(["é–‹å§‹æ™‚é–“", start_time.strftime("%Y-%m-%d %H:%M:%S")])
        writer.writerow(["çµæŸæ™‚é–“", end_time.strftime("%Y-%m-%d %H:%M:%S")])
        writer.writerow(["ç¸½è€—æ™‚", str(elapsed)])
        if count_success > 0:
            avg_time = elapsed.total_seconds() / count_success
            writer.writerow(["å¹³å‡æ¯å¼µåœ–ç‰‡è™•ç†æ™‚é–“ (ç§’)", f"{avg_time:.2f}"])
        else:
            writer.writerow(["å¹³å‡æ¯å¼µåœ–ç‰‡è™•ç†æ™‚é–“", "ç„¡æ³•è¨ˆç®—"])

        writer.writerow([])  # ç©ºè¡Œåˆ†éš”å€å¡Š

        writer.writerow(["ğŸ“¦ å£“ç¸®ç¸½çµ"])
        writer.writerow(["é …ç›®", "æ•¸å€¼"])
        writer.writerow(["ç¸½åœ–ç‰‡æ•¸é‡", total_files])
        writer.writerow(["æˆåŠŸå£“ç¸®", count_success])
        writer.writerow(["å·²å‚™ä»½/è·³é", count_original_backups])
        writer.writerow(["_skip å‘½åè·³é", count_skipped - count_original_backups])
        writer.writerow(["åœ–ç‰‡æ‰“é–‹éŒ¯èª¤/éæ”¯æ´", count_unreadable])
        writer.writerow(["å£“ç¸®éŒ¯èª¤", count_error])
        writer.writerow(["åŸå§‹ç¸½å¤§å° (MB)", f"{total_before / 1024 / 1024:.2f}"])
        writer.writerow(["å£“ç¸®å¾Œå¤§å° (MB)", f"{total_after / 1024 / 1024:.2f}"])
        if total_before:
            percent_saved = (total_before - total_after) / total_before * 100
            writer.writerow(["ç¯€çœç©ºé–“ (MB)", f"{(total_before - total_after) / 1024 / 1024:.2f}"])
            writer.writerow(["ç¯€çœç™¾åˆ†æ¯” (%)", f"{percent_saved:.1f}"])

        writer.writerow([])  # ç©ºè¡Œåˆ†éš”å€å¡Š

        # ç¬¬äºŒæ®µï¼šå‰¯æª”åçµ±è¨ˆ
        writer.writerow(["ğŸ“ å„å‰¯æª”åé¡å‹çµ±è¨ˆ"])
        writer.writerow(["å‰¯æª”å", "åœ–ç‰‡æ•¸é‡", "åŸå§‹å¤§å° (MB)", "å£“ç¸®å¾Œå¤§å° (MB)", "ç¯€çœç©ºé–“ (MB)", "ç¯€çœç™¾åˆ†æ¯” (%)"])
        for ext, stats in ext_stats.items():
            before_mb = stats["before"] / 1024 / 1024
            after_mb = stats["after"] / 1024 / 1024
            savings = before_mb - after_mb
            percent = (savings / before_mb * 100) if before_mb > 0 else 0
            writer.writerow([
                ext.upper(),
                stats["count"],
                f"{before_mb:.2f}",
                f"{after_mb:.2f}",
                f"{savings:.2f}",
                f"{percent:.1f}"
            ])
        
        writer.writerow([])  # ç©ºè¡Œåˆ†éš”å€å¡Š

        # ç¬¬ä¸‰æ®µï¼šæ¯å¼µåœ–ç‰‡è©³ç´°è³‡æ–™
        writer.writerow(["æª”æ¡ˆè©³ç´°æƒ…æ³"])
        writer.writerow(["æª”æ¡ˆè·¯å¾‘", "å‰¯æª”å", "åŸå§‹å¤§å° (KB)", "å£“ç¸®å¾Œå¤§å° (KB)", "ç¯€çœç™¾åˆ†æ¯” (%)", "ç‹€æ…‹", "è™•ç†æ™‚é–“"])
        for file_path, before, after, status, ext, timestamp in results:
            if before and after:
                percent = (before - after) / before * 100
                writer.writerow([
                    file_path,
                    ext,
                    f"{before / 1024:.1f}",
                    f"{after / 1024:.1f}",
                    f"{percent:.1f}",
                    status,
                    timestamp
                ])
            else:
                writer.writerow([file_path, ext, "", "", "", status, timestamp])



    print(f"\nğŸ“ å£“ç¸®å ±è¡¨å·²å„²å­˜è‡³ï¼š{csv_path}")


if __name__ == "__main__":
    target_dir = input("è«‹è¼¸å…¥è¦è™•ç†çš„è³‡æ–™å¤¾è·¯å¾‘ï¼š").strip()
    if os.path.isdir(target_dir):
        process_directory(target_dir)
        print(f"è³‡æ–™å¤¾ '{target_dir}' è™•ç†å®Œæˆï¼")
    else:
        print("è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œè«‹é‡æ–°ç¢ºèªè·¯å¾‘ã€‚")

